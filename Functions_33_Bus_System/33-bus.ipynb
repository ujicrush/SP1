{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bcbdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import gurobipy as gp\n",
    "import warnings\n",
    "import time\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abbcd7",
   "metadata": {},
   "source": [
    "### 主问题求解(cut的生成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30d33371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Allocation_2D(\n",
    "        iter, NP, N_Bus, ESS_candidate, R_bounds, C_bounds, obj_2nd, lambda_2nd, mu_2nd, \n",
    "        previous_rating, previous_cap, Fixed_cost, Power_rating_cost, Energy_capacity_cost, C_rate=1):\n",
    "\n",
    "    print(\"start solving master problem...\")\n",
    "\n",
    "    # Unfolding data:\n",
    "    R_min = R_bounds[0]\n",
    "    R_max = R_bounds[1]\n",
    "    C_min = C_bounds[0]\n",
    "    C_max = C_bounds[1]\n",
    "\n",
    "    # Adding variables for MILP\n",
    "    U = cp.Variable((N_Bus), boolean=True) # Location for ESS solutions\n",
    "    Cap_U = cp.Variable(N_Bus)  # Continuous variable representing the maximum energy storage capacity at each node.\n",
    "    Rating_U = cp.Variable(N_Bus)  # Continuous variable representing the maximum energy storage rating at each node.\n",
    "    alpha = cp.Variable() # using for benders decomposition\n",
    "\n",
    "    #Values that need to be calculated\n",
    "    non_candidate = np.ones(N_Bus)\n",
    "    non_candidate[ESS_candidate] = 0 # Usefull to constraint the location of ESS storage system to only candidate nodes\n",
    "\n",
    "    # Constraints: \n",
    "    constraints = []\n",
    "    # Physical limits on power and capacity\n",
    "    constraints += [Rating_U >= cp.multiply(R_min, U), Rating_U <= cp.multiply(R_max, U)] # Constraint rating to max and min values\n",
    "    constraints += [Cap_U >= cp.multiply(C_min, U), Cap_U <= cp.multiply(C_max, U)] # Constraint capacity to max and min values\n",
    "    constraints.append(cp.multiply(non_candidate,U) == np.zeros(N_Bus))\n",
    "    constraints.append(C_rate * Cap_U >= Rating_U)\n",
    "\n",
    "    # Benders decompositions \n",
    "    bdcut = []  # Multi-cut\n",
    "    bdcut2 = []  # Single-cut\n",
    "\n",
    "    for k in range(iter):\n",
    "        for sc in range(NP):\n",
    "            bdcut.append(alpha >= obj_2nd[sc, k] + \n",
    "                        cp.sum(lambda_2nd[sc, :, :, k], axis=1) @ (Rating_U - previous_rating[:, k]) + \n",
    "                        cp.sum(mu_2nd[sc, :, :, k], axis=1) @ (Cap_U - previous_cap[:, k]))\n",
    "\n",
    "        bdcut2.append(alpha >= cp.sum(obj_2nd[:, k]) + \n",
    "                    np.sum(np.sum(lambda_2nd[:, :, :, k], axis=2), axis=0).T @ (Rating_U - previous_rating[:, k]) + \n",
    "                    np.sum(np.sum(mu_2nd[:, :, :, k], axis=2), axis=0).T @ (Cap_U - previous_cap[:, k]))\n",
    "\n",
    "    constraints += bdcut2 + [alpha >= 0] + bdcut\n",
    "\n",
    "    # Objective function\n",
    "    objective = (\n",
    "        cp.multiply(Fixed_cost, cp.sum(U)) + \n",
    "        cp.multiply(Power_rating_cost, cp.sum(Rating_U)) + \n",
    "        cp.multiply(Energy_capacity_cost, cp.sum(Cap_U)) + \n",
    "        alpha\n",
    "    )\n",
    "\n",
    "    # Solve\n",
    "    problem = cp.Problem(cp.Minimize(objective), constraints)\n",
    "    problem.solve(solver=cp.MOSEK)\n",
    "\n",
    "    Investment = (\n",
    "        Fixed_cost * np.sum(U.value) + \n",
    "        Power_rating_cost * np.sum(Rating_U.value) + \n",
    "        Energy_capacity_cost * np.sum(Cap_U.value)\n",
    "    )\n",
    "    \n",
    "    print(\"finish solving master problem\")\n",
    "\n",
    "    return problem.value, Investment, U.value, Rating_U.value, Cap_U.value, alpha.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de92dc",
   "metadata": {},
   "source": [
    "### Incidence_matrices计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1da0df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Incidence_matrices(num_nodes, num_lines, sending_end, receiving_end):\n",
    "    \"\"\"\n",
    "    Create incidence matrices for network topology\n",
    "    \"\"\"\n",
    "    A_plus = np.zeros((num_lines,num_nodes)) # A+ matrix (num_nodes x num_lines)\n",
    "    for l in range(num_lines):\n",
    "        A_plus[l,int(sending_end[l])] = 1\n",
    "        A_plus[l,int(receiving_end[l])] = -1\n",
    "\n",
    "    A_minus = np.zeros((num_lines,num_nodes)) # A- matrix (num_nodes x num_lines)\n",
    "    for l in range(num_lines):\n",
    "        A_minus[l,int(sending_end[l])] = 0\n",
    "        A_minus[l,int(receiving_end[l])] = -1\n",
    "\n",
    "    A_plus = np.transpose(A_plus)\n",
    "    A_minus = np.transpose(A_minus)\n",
    "\n",
    "    return A_plus, A_minus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1944671",
   "metadata": {},
   "source": [
    "### average_cut函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24b4561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_cut_full(NP, NB, NT, R_sample, obj_val_tilde, lambda_val_tilde, mu_val_tilde):\n",
    "    \"\"\"\n",
    "    Expand sampled dual values and objective values to full arrays,\n",
    "    using mean for non-sampled scenarios.\n",
    "    \"\"\"\n",
    "    obj_full = np.zeros(NP)\n",
    "    lambda_full = np.zeros((NP, NB, NT))\n",
    "    mu_full = np.zeros((NP, NB, NT))\n",
    "\n",
    "    # Fill sampled\n",
    "    obj_full[R_sample] = obj_val_tilde\n",
    "    lambda_full[R_sample, :, :] = lambda_val_tilde\n",
    "    mu_full[R_sample, :, :] = mu_val_tilde\n",
    "\n",
    "    # Compute means\n",
    "    obj_mean = np.mean(obj_val_tilde)\n",
    "    lambda_mean = np.mean(lambda_val_tilde, axis=0)  # shape (NB, NT)\n",
    "    mu_mean = np.mean(mu_val_tilde, axis=0)\n",
    "\n",
    "    # Fill non-sampled with mean\n",
    "    not_R_sample = np.setdiff1d(np.arange(NP), R_sample)\n",
    "    obj_full[not_R_sample] = obj_mean\n",
    "    lambda_full[not_R_sample, :, :] = lambda_mean\n",
    "    mu_full[not_R_sample, :, :] = mu_mean\n",
    "\n",
    "    return obj_full, lambda_full, mu_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19d3f3",
   "metadata": {},
   "source": [
    "### 子问题求解(grid operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d4139",
   "metadata": {},
   "source": [
    "#### single scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SOC_ACOPF(sc, NT, baseMVA, N_bus, N_line, Yp, sending_node, receiving_node,\n",
    "                      R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n,\n",
    "                      K_l, a, b, c, ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound, Pn_solar_bound, freq_scenario):\n",
    "\n",
    "    # Extract time-dependent indices\n",
    "    idx_PV_sc = [np.where(Pn_solar_bound[sc, 1, :, time] > 0)[0].astype(int) for time in range(NT)]\n",
    "    Yp_scenario = Yp * freq_scenario\n",
    "\n",
    "    try:\n",
    "        print(f\"Starting scenario {sc}\", flush=True)\n",
    "        # Call the SOC_ACOPF_2D_alocation function\n",
    "        # solving sub-problem to get ub and dual solutions\n",
    "        cost, _, _, _, _, _, _, _, _, _, _, _, _, _, _, lambda_aloc, mu_aloc = SOC_ACOPF_2D_alocation(\n",
    "            baseMVA, NT, N_bus, N_line, Yp_scenario[sc], sending_node, receiving_node, idx_PV_sc,\n",
    "            R_l, X_l, B_l, Pd[sc], Qd[sc],\n",
    "            pn_bound[sc], qn_bound, v_bound,\n",
    "            G_n, B_n, K_l,\n",
    "            a, b, c,\n",
    "            ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound)\n",
    "\n",
    "        print(f\"Finished scenario {sc}: Cost = {cost}\", flush=True)\n",
    "        # Return the results for storage\n",
    "        return cost, lambda_aloc, mu_aloc\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in compute_SOC_ACOPF for scenario {sc}: {e}\", flush=True)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c4326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SOC_ACOPF_2D_alocation(baseMVA, NT, num_nodes, num_lines, Yp, sending_node, receiving_node, IndPV,\n",
    "               R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n, K_l, quad_cost, lin_cost, const_cost,\n",
    "               ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound, \n",
    "               theta_n_min=-1, theta_n_max=-1, theta_l_min=-1, theta_l_max=-1, eta_dis = 1, eta_cha = 1):\n",
    "\n",
    "    ######################################################\n",
    "    \"\"\"This model is very usefull since it allows to compute the optimal power flow for any grid topology.\"\"\"\n",
    "    ######################################################\n",
    "    \"\"\"Inputs\"\"\"\n",
    "    # baseMVA : size(1) : Power base in MVA\n",
    "    # NT : size(1) : Number of time steps\n",
    "    # num_nodes : size(1) : Number of buses in the grid (NB)\n",
    "    # num_lines : size(1) : Number of lines in the grid (NL)\n",
    "    # Yp : size(1) : Planning period\n",
    "    # sending_node : size(NB) : array with the sending node with number from 0 to N_bus-1 for line l \n",
    "    # sending_node : size(NL) : array with the receiving node with number from 0 to N_bus-1 for line l\n",
    "    # IndPV : Indexes of PV : List where are the PV\n",
    "    \"\"\"All values in p.u. except the cost functions [CHF/MW]\"\"\"\n",
    "    # quad_cost : Quadratic cost coefficient\n",
    "    # lin_cost : Linear cost coefficient\n",
    "    # const_cost : Constant cost coefficient\n",
    "    # R_l, X_l, B_l, K_l : size(NL,NT) : r, x, b, ampacity limit for each line at each time step for each line\n",
    "    # p_d, q_d, G_n, B_n : size(NB,NT) : active power, reactive power, g and b, at each time step for each node\n",
    "    # pn_bound, qn_bound, v_bound : size(2,NB,NT) : active power, reactive power and voltage magnitude bounds at each time step for each node\n",
    "    # quad_cost, lin_cost, const_cost : size(NB,NT) : cost of each buses.\n",
    "    # ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound : size(2,NB,NT) : ESS initial state and bounds for rating and capacity\n",
    "    ######################################################\n",
    "    \"\"\"Output\"\"\"\n",
    "    # problem : size(1) : Total cost of operation\n",
    "    # p_n, q_n, v_n : size(NB,NT) : active power injection, reactive power injection and voltage magnitude at each time step for each node\n",
    "    # p_sl, q_sl, p_ol, q_ol, K_ol : size(NL,NT) : active and reactive power flow on lines, active and reactive power flow losses on lines, ampacity losses\n",
    "    # theta_n, theta_l : size(NB or NL,NT) : angles on buses and lines\n",
    "    # ESS_soc, ESS_cha, ESS_dis, q_ESS : size(NB,NT) : ESS operation variables \n",
    "    # lambda_, mu_ : size(NB,NT) : Dual values of ESS constraints on rating and capacity\n",
    "    ######################################################\n",
    "    \n",
    "    \"\"\"Initialisation\"\"\"\n",
    "    A_plus, A_minus = Incidence_matrices(num_nodes, num_lines, sending_node, receiving_node)\n",
    "\n",
    "    # Unfolding nodes data\n",
    "    p_n_min = pn_bound[0]  # Minimum active power generation at each node\n",
    "    p_n_max = pn_bound[1]  # Maximum active power generation at each node\n",
    "    q_n_min = qn_bound[0]  # Minimum reactive power generation at each node\n",
    "    q_n_max = qn_bound[1]  # Maximum reactive power generation at each node\n",
    "    V_min = v_bound[0]**2  # Minimum voltage squared at each node\n",
    "    V_max = v_bound[1]**2  # Maximum voltage squared at each node\n",
    "    ESS_cha_min = ESS_cha_bound[0] # Minimum charging rate at each node \n",
    "    ESS_cha_max = ESS_cha_bound[1] # Maximum charging rate at each node\n",
    "    ESS_dis_min = ESS_dis_bound[0] # Minimum discharging rate at each node \n",
    "    ESS_dis_max = ESS_dis_bound[1] # Maximum discharging rate at each node\n",
    "    ESS_soc_min = ESS_soc_bound[0] # Minimum state of charge at each node \n",
    "    ESS_soc_max = ESS_soc_bound[1] # Maximum state of charge at each node\n",
    "\n",
    "    # theta_n min and max\n",
    "    if theta_n_min == -1 : theta_n_min = - np.pi / 2 * np.ones((num_nodes,NT))  # Minimum bus angle \n",
    "    if theta_n_max == -1 : theta_n_max = np.pi / 2 * np.ones((num_nodes,NT))  # Maximum bus angle\n",
    "\n",
    "    # theta_l min and max\n",
    "    if theta_l_min == -1 : theta_l_min = - np.pi / 2 * np.ones((num_lines,NT))  # Minimum line angle (from relaxation assumption)\n",
    "    if theta_l_max == -1 : theta_l_max = np.pi / 2 * np.ones((num_lines,NT))  # Maximum line angle (from relaxation assumption)\n",
    "\n",
    "    # for q_ESS\n",
    "    lin = 2 # from data\n",
    "    xx = np.linspace(0, 1/2 * np.pi, lin + 1)\n",
    "    slope = np.zeros(lin)\n",
    "    offset = np.zeros(lin)\n",
    "    for i in range(lin):\n",
    "        slope[i]=(np.sin(xx[i+1])-np.sin(xx[i]))/(np.cos(xx[i+1])-np.cos(xx[i]))\n",
    "        offset[i]=(np.sin(xx[i])*np.cos(xx[i+1])-np.sin(xx[i+1])*np.cos(xx[i]))/(np.cos(xx[i+1])-np.cos(xx[i]))\n",
    "\n",
    "    ######################################################\n",
    "    \"\"\"Variables\"\"\"\n",
    "    p_n = cp.Variable((num_nodes,NT))  # Active power at node n\n",
    "    p_curtailment = cp.Variable((num_nodes, NT), nonneg=True)\n",
    "    p_slack = p_n[0, :]\n",
    "    p_imp = cp.pos(p_slack)\n",
    "    p_exp = cp.pos(-p_slack)\n",
    "    q_n = cp.Variable((num_nodes,NT))  # Reactive power at node n\n",
    "    V_n = cp.Variable((num_nodes, NT))  # Voltage magnitude squared at node n\n",
    "    theta_n = cp.Variable((num_nodes,NT))  # Voltage angles at node n\n",
    "    p_sl = cp.Variable((num_lines,NT))  # Active power at sending end of line l\n",
    "    q_sl = cp.Variable((num_lines,NT))  # Reactive power at sending end of line l\n",
    "    p_ol = cp.Variable((num_lines,NT))  # Active power losses on line l\n",
    "    q_ol = cp.Variable((num_lines,NT))  # Reactive power losses on line l\n",
    "    K_ol = cp.Variable((num_lines,NT))  # Branch Equivalent ampacity constraint on line l\n",
    "    theta_l = cp.Variable((num_lines,NT))  # Voltage angles at line l\n",
    "\n",
    "    ESS_cha = cp.Variable((num_nodes,NT)) \n",
    "    ESS_dis = cp.Variable((num_nodes,NT))\n",
    "    ESS_soc = cp.Variable((num_nodes,NT))\n",
    "    q_ESS = cp.Variable((num_nodes,NT))\n",
    "    \n",
    "    # Variables for allocation\n",
    "    Cmax = cp.Variable((num_nodes,NT))\n",
    "    Rmax = cp.Variable((num_nodes,NT))\n",
    "\n",
    "    # Create the Incidence Matrices used in the sending end and receiving end voltage\n",
    "    Inc_sending_cvx = np.zeros((num_lines, num_nodes))\n",
    "    Inc_receiving_cvx = np.zeros((num_lines, num_nodes))\n",
    "    for l in range(num_lines):\n",
    "        Inc_sending_cvx[l, sending_node[l]] = 1\n",
    "        Inc_receiving_cvx[l, receiving_node[l]] = 1\n",
    "\n",
    "    ######################################################\n",
    "    \"\"\" Constraints\"\"\"\n",
    "    constraints = []\n",
    "    objective = 0\n",
    "    \n",
    "    ### Bus constraints ###\n",
    "\n",
    "    # Voltage Magnitude bounds (1k)\n",
    "    constraints.append(V_n >= V_min)\n",
    "    constraints.append(V_n <= V_max)\n",
    "\n",
    "    # Node angle bounds (1m)\n",
    "    constraints.append(theta_n >= theta_n_min)\n",
    "    constraints.append(theta_n <= theta_n_max)\n",
    "\n",
    "    # Active power bounds (1n)\n",
    "    constraints.append(p_n >= p_n_min)\n",
    "    constraints.append(p_n <= p_n_max)\n",
    "\n",
    "    # for time in range(NT):\n",
    "    #     if len(IndPV[time])>0:\n",
    "    #         constraints.append(p_n[IndPV[time],:] == p_n_max[IndPV[time],:]) # enforces the power injection to be equal to PV production\n",
    "\n",
    "    for time in range(NT):\n",
    "        if len(IndPV[time]) > 0:\n",
    "            # p_n + p_curtailment = p_n_max\n",
    "            constraints.append(p_n[IndPV[time], :] + p_curtailment[IndPV[time], :] == p_n_max[IndPV[time], :])\n",
    "\n",
    "    # Reactive power bounds (1o)\n",
    "    constraints.append(q_n >= q_n_min)\n",
    "    constraints.append(q_n <= q_n_max)\n",
    "\n",
    "    # Alocation related constraints to get the dual variables\n",
    "    constraint_capacity = Cmax == ESS_soc_max\n",
    "    constraint_rating = Rmax == ESS_cha_max\n",
    "    constraints += [constraint_capacity, constraint_rating]\n",
    "\n",
    "    # ESS charging and discharging rate bounds\n",
    "    constraints.append(ESS_cha >= ESS_cha_min)\n",
    "    constraints.append(ESS_cha <= Rmax)\n",
    "    constraints.append(ESS_dis >= ESS_dis_min)\n",
    "    constraints.append(ESS_dis <= Rmax)\n",
    "\n",
    "    # ESS SOC bounds\n",
    "    constraints.append(ESS_soc >= ESS_soc_min)\n",
    "    constraints.append(ESS_soc <= Cmax)\n",
    "\n",
    "    # Linking time steps for ESS (excluding the last time step)\n",
    "    constraints.append(ESS_soc[:, 1:] == ESS_soc[:, :-1] + ESS_cha[:, :-1] - ESS_dis[:, :-1])\n",
    "    constraints.append(ESS_soc0 == ESS_soc[:,-1] + ESS_cha[:,-1] - ESS_dis[:,-1]) #last timestep to reset battery charge for next day\n",
    "\n",
    "    # Initializing ESS SOC for the first time step\n",
    "    constraints.append(ESS_soc[:, 0] == ESS_soc0)\n",
    "    constraints.append(ESS_soc[:,-1] == ESS_soc0)\n",
    "    constraints.append(cp.sum(ESS_cha,axis=1) == cp.sum(ESS_dis,axis=1))\n",
    "\n",
    "    # Battery aging constraints --> battery has to do at maximum 1.1 cycles per day\n",
    "    constraints.append(cp.sum(cp.abs(ESS_cha-ESS_dis),axis=1) <= 2*1.1*Cmax[:,0])\n",
    "\n",
    "    # ESS reactive power computation and bounds\n",
    "    for i in range(lin):\n",
    "        constraints.append(q_ESS <= slope[i] * (ESS_cha - ESS_dis) + offset[i] * Rmax)\n",
    "        constraints.append(q_ESS <= -slope[i] * (ESS_cha - ESS_dis) + offset[i] * Rmax)\n",
    "        constraints.append(q_ESS >= slope[i] * (ESS_cha - ESS_dis) - offset[i] * Rmax)\n",
    "        constraints.append(q_ESS >= -slope[i] * (ESS_cha - ESS_dis) - offset[i] * Rmax)\n",
    "\n",
    "    # Active Power Balance (1b)\n",
    "    constraints.append(p_n + ESS_dis - Pd - ESS_cha == A_plus @ p_sl - A_minus @ p_ol + cp.multiply(G_n, V_n))\n",
    "\n",
    "    # Reactive Power Balance (1c)\n",
    "    constraints.append(q_n - q_ESS - Qd == A_plus @ q_sl - A_minus @ q_ol - cp.multiply(B_n, V_n))\n",
    "\n",
    "    ### line constraints ###\n",
    "\n",
    "    # Line angle bounds (1l):\n",
    "    constraints.append(theta_l >= theta_l_min)\n",
    "    constraints.append(theta_l <= theta_l_max)\n",
    "\n",
    "    # Voltage drop constraint (1d):\n",
    "    constraints.append(Inc_sending_cvx @ V_n - Inc_receiving_cvx @ V_n== 2 * cp.multiply(R_l, p_sl) + 2 * cp.multiply(X_l, q_sl) - cp.multiply(R_l, p_ol) - cp.multiply(X_l, q_ol))\n",
    "    \n",
    "    # Conic active and reactive power losses constraint (2b):\n",
    "    constraints.append(K_ol == cp.multiply((K_l - cp.multiply(Inc_sending_cvx @ V_n, B_l**2) + 2 * cp.multiply(q_sl, B_l)), X_l))\n",
    "    constraints.append(K_ol >= q_ol)\n",
    "\n",
    "    # Power loss constraint (2c):\n",
    "    constraints.append(cp.multiply(p_ol,X_l) == cp.multiply(q_ol,R_l))\n",
    "\n",
    "    # Line angle constraint (1h):\n",
    "    constraints.append(theta_l == Inc_sending_cvx @ theta_n - Inc_receiving_cvx @ theta_n)\n",
    "\n",
    "    # Linearized angle constraint (2d):\n",
    "    constraints.append(theta_l == cp.multiply(X_l,p_sl) - cp.multiply(R_l,q_sl))\n",
    "\n",
    "    # Constraints that requiere a loop because of dimensionality limit of cp.norm().\n",
    "    for time in range(NT):\n",
    "        for l in range(num_lines):\n",
    "            # Conic active and reactive power losses constraint (2b): (rest of ineq)\n",
    "            constraints.append(\n",
    "                cp.norm(\n",
    "                    cp.vstack([\n",
    "                        2 *np.sqrt(X_l[l,time])* cp.vstack([p_sl[l,time], q_sl[l,time]]),\n",
    "                        cp.reshape(q_ol[l,time] - V_n[sending_node[l],time], (1, 1))\n",
    "                    ]),2\n",
    "                ) <= q_ol[l,time] + V_n[sending_node[l],time]\n",
    "            )\n",
    "\n",
    "            # Feasibility solution recovery equation (4g):\n",
    "            constraints.append(\n",
    "                V_n[sending_node[l],time] + V_n[receiving_node[l],time] >= cp.norm(\n",
    "                    cp.vstack([\n",
    "                        2*theta_l[l,time]/np.sin(theta_l_max[l,time]), \n",
    "                        V_n[sending_node[l],time] - V_n[receiving_node[l],time]\n",
    "                    ]), 2)\n",
    "            )\n",
    "    \n",
    "\n",
    "    #####################################################################\n",
    "    \"\"\"Objective Function\"\"\" \n",
    "    curtailment_cost = 26\n",
    "    price_imp = [620, 620, 620, 620, 620, 620, 620, 890, 890, 890, 890, 890, 890, 890, 890, 890, 890, 890, 890, 890, 890, 620, 620, 620]\n",
    "    objective = cp.Minimize(\n",
    "        Yp * 365 * (cp.sum(cp.multiply(quad_cost, cp.square(p_n * baseMVA)) \n",
    "                        + cp.multiply(lin_cost, p_n * baseMVA) \n",
    "                       + const_cost)) \n",
    "        + Yp * 2910 * cp.sum(ESS_cha + ESS_dis) * baseMVA\n",
    "        + cp.sum(p_ol) * 100 * 365 * baseMVA * Yp\n",
    "        + cp.sum(cp.multiply(p_imp, price_imp)) * 365 * baseMVA * Yp\n",
    "        + cp.sum(p_exp) * 100 *365 *baseMVA * Yp\n",
    "        + cp.sum(p_curtailment * baseMVA) * curtailment_cost * Yp * 365\n",
    "    )\n",
    "\n",
    "    # Defining the optimization problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    #####################################################################\n",
    "\n",
    "    #####################################################################\n",
    "    # Solve the problem\n",
    "    problem.solve(solver=cp.MOSEK)\n",
    "\n",
    "    # Dual values :\n",
    "    lambda_ = constraint_rating.dual_value # Dual value for the constraint related to ESS maximal rating\n",
    "    mu_ = constraint_capacity.dual_value # Dual value for the constraint related to ESS maximal capacity\n",
    "\n",
    "    return problem.value, p_n.value, q_n.value, np.sqrt(V_n.value), p_sl.value, q_sl.value, p_ol.value, q_ol.value, K_ol.value, theta_n.value, theta_l.value, ESS_soc.value, ESS_cha.value, ESS_dis.value, q_ESS.value, lambda_, mu_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0faf9b",
   "metadata": {},
   "source": [
    "#### all scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13504e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SOC_ACOPF_for_samples(NP, R_sample, NT, baseMVA, N_bus, N_line, Yp, sending_node, receiving_node,\n",
    "                              R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n,\n",
    "                              K_l, a, b, c, ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound,\n",
    "                              Pn_solar_bound, freq_scenario):\n",
    "    lambda_list = []\n",
    "    mu_list = []\n",
    "    obj_list = []\n",
    "\n",
    "    for sc in R_sample:\n",
    "        obj_val, lambda_val, mu_val = compute_SOC_ACOPF(\n",
    "            sc, NT, baseMVA, N_bus, N_line, Yp, sending_node, receiving_node,\n",
    "            R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n,\n",
    "            K_l, a, b, c, ESS_soc0, ESS_cha_bound, ESS_dis_bound,\n",
    "            ESS_soc_bound, Pn_solar_bound, freq_scenario\n",
    "        )\n",
    "        obj_list.append(obj_val)\n",
    "        lambda_list.append(lambda_val)\n",
    "        mu_list.append(mu_val)\n",
    "\n",
    "    lambda_array = np.stack(lambda_list, axis=0)\n",
    "    mu_array = np.stack(mu_list, axis=0)\n",
    "    obj_array = np.array(obj_list)\n",
    "\n",
    "    obj_full, lambda_full, mu_full = average_cut_full(NP, N_bus, NT, R_sample, obj_array, lambda_array, mu_array)\n",
    "\n",
    "    return obj_full, lambda_full, mu_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f0f7c2",
   "metadata": {},
   "source": [
    "### 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c023bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "\n",
    "    ################################################################ Parameters\n",
    "    ESS_candidate = np.array([8, 18, 25, 33]) #Candidates nodes\n",
    "    num_processes = 4 # Number of processes to use (adjust based on your CPUs and memory)\n",
    "    lim_iter = 100 # Max number of iteration of benders decompositions\n",
    "    datapath = \"Data/\" # Change as a function of the loaded folder\n",
    "    # It is possible to change other vales such as prices and costs detailed later\n",
    "\n",
    "    ############################################################### Data import\n",
    "    # Calculate time\n",
    "    start_time = dt.datetime.now()\n",
    "    sample_time = start_time\n",
    "\n",
    "    # data for 33-bus system \n",
    "    bus_data = pd.read_csv(datapath+\"bus_data.csv\")\n",
    "    # bus_data = bus_data.sort_values(by=\"BUS_I\").reset_index(drop=True) # maybe not usefull, to test later\n",
    "    # bus_index_to_bus_name = bus_data['BUS_I'].to_dict() # dictionary mapping the index number to bus ID\n",
    "    # bus_name_to_bus_index = {v: k for k, v in bus_index_to_bus_name.items()}\n",
    "    # bus_data = bus_data.reset_index().rename(columns = {\"index\":\"grid_node\"})\n",
    "\n",
    "    branch_data = pd.read_csv(datapath+\"branch_data.csv\")\n",
    "    generator_data = pd.read_csv(datapath+\"generator_data.csv\")\n",
    "\n",
    "    # stat_scenario = pd.read_csv(datapath+\"Chaudron_scenarios.csv\",delimiter=\";\")\n",
    "    # freq_scenario = stat_scenario.dp.to_numpy() / stat_scenario.dp.sum()\n",
    "\n",
    "    # Processed data to get Pd, Qd and PV production per time step and per Scenario\n",
    "    scenario_data = pd.read_csv(datapath+\"Clean_demand.csv\")\n",
    "\n",
    "    # Used as data cleaning since I had one file with N nodes and the other with N-1 nodes\n",
    "    # I then assumed that the slack was missing so I ajust values to fit \n",
    "    # scenario_data.loc[scenario_data[scenario_data.grid_node>=(bus_data[bus_data.BUS_TYPE==3].grid_node).to_list()[0]].index,\"grid_node\"] += 1 \n",
    "\n",
    "    # NP = len(scenario_data.Period.unique()[:-2])\n",
    "    # N_bus = len(bus_data.grid_node.unique())\n",
    "    # N_line = len(branch_data)\n",
    "    # NT = 24\n",
    "    # baseMVA = generator_data.MBASE.max()\n",
    "\n",
    "    N_bus = len(bus_data.Grid_node.unique())  # 33-bus\n",
    "    N_line = len(branch_data)\n",
    "    NP = len(scenario_data.Scenario.unique())  # 12 scenarios\n",
    "    NT = 24\n",
    "    baseMVA = 10  # 1e7VA=10MVA\n",
    "\n",
    "    freq_scenario = np.ones(NP) / NP\n",
    "\n",
    "    ############################################################## Setting all costs\n",
    "    # PV generation cost\n",
    "    quad_cost_PV = 0\n",
    "    lin_cost_PV = 26\n",
    "    const_cost_PV = 0\n",
    "\n",
    "    # Power cost\n",
    "    # index_slack = (bus_data[bus_data.BUS_TYPE==3].grid_node).to_list()[0]\n",
    "    index_slack = [0]\n",
    "    a_slack = np.zeros(N_bus)\n",
    "    a_slack[index_slack] = 0\n",
    "    a_slack = a_slack[:, np.newaxis] * np.ones((1, NT))\n",
    "    b_slack = np.zeros(N_bus)\n",
    "    b_slack[index_slack] = 200\n",
    "    b_slack = b_slack[:, np.newaxis] * np.ones((1, NT))\n",
    "    c_slack = np.zeros(N_bus)\n",
    "    c_slack[index_slack] = 0\n",
    "    c_slack = c_slack[:, np.newaxis] * np.ones((1, NT))\n",
    "\n",
    "    ############################################################## Data preprocessing\n",
    "    # creating the dataset for values that depends on time and scenario\n",
    "    # Pd = np.zeros((NP, N_bus, NT))\n",
    "    # Pn_solar_bound = np.zeros((NP, 2, N_bus, NT))\n",
    "    # a_PV = np.zeros((N_bus, NT))\n",
    "    # b_PV = np.zeros((N_bus, NT))\n",
    "    # c_PV = np.zeros((N_bus, NT))\n",
    "\n",
    "    # for sc in scenario_data.Period.unique()[:-2]-1:\n",
    "    #     mask1 = (scenario_data.Period==sc+1)\n",
    "    #     for time in scenario_data[mask1].Time.unique()-1:\n",
    "    #         mask2 = (scenario_data.Time==time)\n",
    "    #         intermediate_df = pd.merge(scenario_data[mask1 & mask2][[\"grid_node\",\"Domestic_electricity\",\"PV_production\"]],\n",
    "    #             bus_data[[\"grid_node\"]],\n",
    "    #             on=\"grid_node\",\n",
    "    #             how=\"right\").fillna(0)\n",
    "    #         Pd[sc,:,time] = intermediate_df.Domestic_electricity.to_numpy() /1000 /baseMVA # kWh to MW to p.u. \n",
    "    #         Pn_solar_bound[sc,1,:,time] = intermediate_df.PV_production.to_numpy() /1000 /baseMVA # kWh to MW to p.u.\n",
    "    #         a_PV[:,time] = quad_cost_PV * np.ones(N_bus) # useless in that case since a,b,c constant\n",
    "    #         b_PV[:,time] = lin_cost_PV * np.ones(N_bus) # useless in that case since a,b,c constant\n",
    "    #         c_PV[:,time] = const_cost_PV * np.ones(N_bus) # useless in that case since a,b,c constant\"\"\"\n",
    "\n",
    "    Pd = np.zeros((NP, N_bus, NT))\n",
    "    Qd = np.zeros((NP, N_bus, NT))\n",
    "    Pn_solar_bound = np.zeros((NP, 2, N_bus, NT))\n",
    "    index_PV = [16, 31]\n",
    "    a_PV = np.zeros((N_bus, NT))\n",
    "    b_PV = np.zeros((N_bus, NT))\n",
    "    c_PV = np.zeros((N_bus, NT))\n",
    "\n",
    "    for sc in range(1, NP + 1):\n",
    "        for time in range(1, NT + 1):\n",
    "            mask = (scenario_data.Scenario == sc) & (scenario_data.Time == time)\n",
    "            intermediate_df = pd.merge(\n",
    "                scenario_data[mask][[\"Grid_node\", \"Pd\", \"Qd\", \"PV\"]],\n",
    "                pd.DataFrame({\"Grid_node\": np.arange(1, N_bus + 1)}),\n",
    "                on=\"Grid_node\",\n",
    "                how=\"right\"\n",
    "            ).fillna(0)\n",
    "\n",
    "            Pd[sc-1, :, time-1] = intermediate_df.Pd.to_numpy() / 1000 / baseMVA  # kW to p.u.\n",
    "            Qd[sc-1, :, time-1] = intermediate_df.Qd.to_numpy() / 1000 / baseMVA  # kW to p.u.\n",
    "            Pn_solar_bound[sc-1, 0, :, time-1] = 0\n",
    "            Pn_solar_bound[sc-1, 1, :, time-1] = intermediate_df.PV.to_numpy() / 1000 / baseMVA  # kW to p.u.\n",
    "\n",
    "    a_PV[index_PV, :] = quad_cost_PV\n",
    "    b_PV[index_PV, :] = lin_cost_PV\n",
    "    c_PV[index_PV, :] = const_cost_PV\n",
    "\n",
    "    # expanding dataset for all other data that is not time or scenario dependant\n",
    "    V_base = bus_data.baseKV.max()  # 12.66 kV\n",
    "    Z_base = (V_base ** 2) / baseMVA  # kV^2 / MVA = 16.02756 Ohm\n",
    "\n",
    "    # related to bus data\n",
    "    # q_d = bus_data.Qd.to_numpy() /baseMVA /5 #reactive power demand\n",
    "    # q_d= q_d[:, np.newaxis] * np.ones((1, NT))\n",
    "    G_n = bus_data.Gs.to_numpy() * Z_base\n",
    "    G_n = G_n[:, np.newaxis] * np.ones((1, NT))\n",
    "    B_n = bus_data.Bs.to_numpy() * Z_base\n",
    "    B_n = B_n[:, np.newaxis] * np.ones((1, NT))\n",
    "    v_bound = bus_data[[\"Vmin\",\"Vmax\"]].to_numpy()\n",
    "    v_bound = v_bound.T[:, :, np.newaxis] * np.ones((1, N_bus, NT))\n",
    "\n",
    "    # related to generator data\n",
    "    # pn_bound = np.zeros((N_bus,2))\n",
    "    # qn_bound = np.zeros((N_bus,2))\n",
    "    # index_gen = generator_data[\"GEN_BUS\"].map(bus_name_to_bus_index).to_numpy()\n",
    "    # generator_data[\"bus_index\"] = index_gen\n",
    "    # for _, row in generator_data.iterrows():\n",
    "    #     index = row[\"bus_index\"]\n",
    "    #     pn_bound[index,0] = -row[\"PMAX\"] /baseMVA \n",
    "    #     pn_bound[index,1] = row[\"PMAX\"] /baseMVA \n",
    "    #     qn_bound[index,0] = row[\"QMIN\"] /baseMVA \n",
    "    #     qn_bound[index,1] = row[\"QMAX\"] /baseMVA \n",
    "    # pn_bound = pn_bound.T[np.newaxis,:, :, np.newaxis] * np.ones((NP, 1, N_bus, NT))\n",
    "    # pn_bound += Pn_solar_bound #Add the PV generation to other generation\n",
    "    # qn_bound = qn_bound.T[:, :, np.newaxis] * np.ones((1, N_bus, NT))\n",
    "\n",
    "    # if no generator, only contains PV bound\n",
    "    pn_bound = np.zeros((N_bus, 2))\n",
    "    qn_bound = np.zeros((N_bus, 2)) \n",
    "\n",
    "    slack_Pmax = 1e4  # choose a large headroom in MW\n",
    "    slack_Pmin = -1e4\n",
    "    slack_Qmax = 1e4\n",
    "    slack_Qmin = -1e4\n",
    "    \n",
    "    pn_bound[index_slack, 0] = slack_Pmin / baseMVA\n",
    "    pn_bound[index_slack, 1] = slack_Pmax / baseMVA\n",
    "    qn_bound[index_slack, 0] = slack_Qmin / baseMVA\n",
    "    qn_bound[index_slack, 1] = slack_Qmax / baseMVA\n",
    "\n",
    "    index_gen = (generator_data[\"GEN_BUS\"].astype(int) - 1).values\n",
    "    # generator_data[\"bus_index\"] = index_gen\n",
    "    a_gen = np.zeros(N_bus)\n",
    "    a_gen[index_gen] = [0.12, 0.09]\n",
    "    a_gen = a_gen[:, np.newaxis] * np.ones((1, NT))\n",
    "    b_gen = np.zeros(N_bus)\n",
    "    b_gen[index_gen] = [20, 15]\n",
    "    b_gen = b_gen[:, np.newaxis] * np.ones((1, NT))\n",
    "    c_gen = np.zeros(N_bus)\n",
    "    c_gen[index_gen] = [0, 0]\n",
    "    c_gen = c_gen[:, np.newaxis] * np.ones((1, NT))\n",
    "\n",
    "    pn_bound[index_gen, 0] = generator_data[\"P_min\"].values / baseMVA\n",
    "    pn_bound[index_gen, 1] = generator_data[\"P_max\"].values / baseMVA\n",
    "    qn_bound[index_gen, 0] = generator_data[\"Q_min\"].values / baseMVA\n",
    "    qn_bound[index_gen, 1] = generator_data[\"Q_max\"].values / baseMVA\n",
    "\n",
    "    pn_static = pn_bound.T[np.newaxis, :, :, np.newaxis]  # (1,2,N_bus,1)\n",
    "    qn_static = qn_bound.T[:, :, np.newaxis]  # (2,N_bus,1)\n",
    "\n",
    "    # 2) Broadcast to (NP,2,N_bus,NT)\n",
    "    pn_bound = pn_static * np.ones((NP, 2, N_bus, NT))\n",
    "\n",
    "    # 3) Finally add the PV bounds\n",
    "    pn_bound += Pn_solar_bound  # both are now (NP,2,N_bus,NT)\n",
    "    qn_bound = qn_static * np.ones((2, N_bus, NT))\n",
    "\n",
    "    # related to branch data\n",
    "    # sending_node = branch_data[\"F_BUS\"].map(bus_name_to_bus_index).to_numpy().astype(int)\n",
    "    # receiving_node = branch_data[\"T_BUS\"].map(bus_name_to_bus_index).to_numpy().astype(int)\n",
    "    sending_node = branch_data[\"F_BUS\"].to_numpy().astype(int) - 1  # converted to 0-based\n",
    "    receiving_node = branch_data[\"T_BUS\"].to_numpy().astype(int) - 1  # converted to 0-based\n",
    "    R_l = branch_data[\"BR_R\"].to_numpy() / Z_base\n",
    "    R_l = R_l[:, np.newaxis] * np.ones((1, NT))\n",
    "    X_l = branch_data[\"BR_X\"].to_numpy() / Z_base\n",
    "    X_l = X_l[:, np.newaxis] * np.ones((1, NT))\n",
    "    B_l = branch_data[\"BR_B\"].to_numpy() * Z_base\n",
    "    B_l = B_l[:, np.newaxis] * np.ones((1, NT))\n",
    "    K_l = branch_data[\"Pup\"].to_numpy() / 1000 / baseMVA  # # Ampacity for each line (kW to p.u.)\n",
    "    K_l = K_l[:, np.newaxis] * np.ones((1, NT))\n",
    "    # K_l = 1 * np.ones(len(branch_data))  # Ampacity for each line\n",
    "    # K_l = K_l[:, np.newaxis] * np.ones((1, NT))\n",
    "\n",
    "    # ESS candidate to index\n",
    "    # ESS_candidate = np.vectorize(bus_name_to_bus_index.get)(ESS_candidate).astype(int)\n",
    "    ESS_candidate -= 1\n",
    "\n",
    "    # summing all cost\n",
    "    a = a_slack + a_PV + a_gen\n",
    "    b = b_slack + b_PV + b_gen\n",
    "    c = c_slack + c_PV + c_gen\n",
    "\n",
    "    ###################################################################### Allocations constaints\n",
    "    R_min = 0.05 / baseMVA * np.ones(N_bus)\n",
    "    R_max = 4 / baseMVA * np.ones(N_bus)\n",
    "    R_bounds = np.array([R_min,R_max])\n",
    "    C_min = 0.1 / baseMVA * np.ones(N_bus)\n",
    "    C_max = 7 /baseMVA * np.ones(N_bus)\n",
    "    C_bounds = np.array([C_min,C_max])\n",
    "    Fixed_cost = 100e3                  # CHF/unit suppose to be e3\n",
    "    Power_rating_cost = 20000e3         # CHF/p.u. \n",
    "    Energy_capacity_cost = 30000e3      # CHF/p.u. \n",
    "\n",
    "    ################################################################# MILP\n",
    "    Yp = 10\n",
    "\n",
    "    # obj_2nd = np.zeros((NP,lim_iter)) # objective function result from the 2nd step (SOC-ACOPF) \n",
    "    # lambda_2nd = np.zeros((NP,N_bus,NT,lim_iter)) # dual variable lambda result from the 2nd step (SOC-ACOPF) \n",
    "    # mu_2nd = np.zeros((NP,N_bus,NT,lim_iter)) # dual variable mu result from the 2nd step (SOC-ACOPF) \n",
    "    previous_rating = np.zeros((N_bus,lim_iter)) # saved rating value from iter = iter-1\n",
    "    previous_cap = np.zeros((N_bus,lim_iter)) # saved capacity value from iter = iter-1\n",
    "    ESS_loc = np.zeros((N_bus,lim_iter))\n",
    "    alpha_store = np.zeros(lim_iter)\n",
    "    upperB_save = np.zeros(lim_iter)\n",
    "    lowerB_save = np.zeros(lim_iter)\n",
    "    fairness_price = np.zeros(lim_iter)\n",
    "    invest_save = np.zeros(lim_iter)\n",
    "    Elapsed_time = np.zeros(lim_iter)\n",
    "\n",
    "    iter = 0\n",
    "    convergence = 0\n",
    "    R_div = 4\n",
    "    obj_2nd = []              # list of list: obj_2nd[iter][m] = shape (NP,)\n",
    "    lambda_2nd = []           # lambda_2nd[iter][m] = shape (NP, NB, NT)\n",
    "    mu_2nd = []               # same shape\n",
    "\n",
    "    while ((iter < lim_iter) & (convergence==0)):\n",
    "        obj_iter = []\n",
    "        lambda_iter = []\n",
    "        mu_iter = []\n",
    "        # master problem solving...\n",
    "        obj_MP, invest_save[iter], ESS_loc[:,iter], Max_rating, Max_capacity, alpha_store[iter] = Allocation_2D(\n",
    "            iter, NP, N_bus, ESS_candidate, R_bounds, C_bounds, \n",
    "            obj_2nd, lambda_2nd, mu_2nd, \n",
    "            previous_rating, previous_cap, \n",
    "            Fixed_cost, Power_rating_cost, Energy_capacity_cost\n",
    "        )\n",
    "\n",
    "        ################################################################## Battery Alocation \n",
    "        IndESS = np.where(ESS_loc[:,iter]==1)[0]\n",
    "\n",
    "        # Charging limits\n",
    "        ESS_cha_l = np.zeros((N_bus, NT))  # Lower charging limits\n",
    "        ESS_cha_u = np.zeros((N_bus, NT))  # Upper charging limits\n",
    "        ESS_cha_u[IndESS, :] = Max_rating[IndESS].reshape(-1, 1)  # Max charging limits\n",
    "        # Discharging limits\n",
    "        ESS_dis_l = np.zeros((N_bus, NT))  # Lower discharging limits\n",
    "        ESS_dis_u = np.zeros((N_bus, NT))  # Upper discharging limits\n",
    "        ESS_dis_u[IndESS, :] = Max_rating[IndESS].reshape(-1, 1)  # Max discharging limits\n",
    "\n",
    "        # State of Charge (SoC)\n",
    "        ESS_soc0 = np.zeros((N_bus))\n",
    "        ESS_soc_l = np.zeros((N_bus, NT))  # Lower SoC limits\n",
    "        ESS_soc_u = np.zeros((N_bus, NT))  # Upper SoC limits\n",
    "        ESS_soc_u[IndESS, :] = Max_capacity[IndESS].reshape(-1, 1)   # Max SoC limits\n",
    "\n",
    "        ESS_cha_bound = np.array([ESS_cha_l,ESS_cha_u])\n",
    "        ESS_dis_bound = np.array([ESS_dis_l,ESS_dis_u])\n",
    "        ESS_soc_bound = np.array([ESS_soc_l,ESS_soc_u])\n",
    "\n",
    "        ###################################################################### 2nd stage SOC-ACOPF\n",
    "        R_sample_size = int(np.ceil(NP / R_div))\n",
    "        total_budget = NP\n",
    "        M = max(1, int(total_budget / R_sample_size))\n",
    "\n",
    "        for m in range(M):\n",
    "            R_sample = np.random.choice(range(NP), size=R_sample_size, replace=False)\n",
    "            obj_full, lambda_full, mu_full = run_SOC_ACOPF_for_samples(NP, R_sample, NT, baseMVA, N_bus, N_line, Yp, sending_node, receiving_node,\n",
    "                                R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n,\n",
    "                                K_l, a, b, c, ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound,\n",
    "                                Pn_solar_bound, freq_scenario)\n",
    "            obj_iter.append(obj_full)\n",
    "            lambda_iter.append(-lambda_full)\n",
    "            mu_iter.append(-mu_full)\n",
    "        obj_2nd.append(obj_iter)\n",
    "        lambda_2nd.append(lambda_iter)\n",
    "        mu_2nd.append(mu_iter)\n",
    "\n",
    "        previous_rating[:,iter] = Max_rating\n",
    "        previous_cap[:,iter] = Max_capacity\n",
    "\n",
    "        ################################################################### Checking Convergence \n",
    "        confidence_level = 0.90\n",
    "        Z = norm.ppf((1 + confidence_level) / 2)  # ~1.64\n",
    "\n",
    "        W_sample = np.random.choice(range(NP), size=R_sample_size, replace=False)\n",
    "        W = len(W_sample)\n",
    "        obj_W, lambda_W, mu_W = run_SOC_ACOPF_for_samples(NP, W_sample, NT, baseMVA, N_bus, N_line, Yp, sending_node, receiving_node,\n",
    "                    R_l, X_l, B_l, Pd, Qd, pn_bound, qn_bound, v_bound, G_n, B_n,\n",
    "                    K_l, a, b, c, ESS_soc0, ESS_cha_bound, ESS_dis_bound, ESS_soc_bound,\n",
    "                    Pn_solar_bound, freq_scenario)\n",
    "        \n",
    "        U_tilde = (NP / W) * np.sum(obj_W[W_sample]) + invest_save[iter] + fairness_price[iter]\n",
    "        s_U = np.sqrt(1 / (W - 1) * np.sum((obj_W[W_sample] - np.mean(obj_W[W_sample])) ** 2))\n",
    "\n",
    "        upper_confidence_bound = U_tilde + Z * s_U / np.sqrt(W)\n",
    "\n",
    "        upperB_save[iter] = upper_confidence_bound\n",
    "        lowerB_save[iter] = obj_MP\n",
    "\n",
    "        confidence_adjusted_bound_gap = (upperB_save[iter] - lowerB_save[iter]) / upperB_save[iter]\n",
    "        e_parameter = -0.0001\n",
    "\n",
    "        if (confidence_adjusted_bound_gap < e_parameter) or (R_div == 1):\n",
    "            print(f\"Iteration {iter}, Gap: {abs(upperB_save[iter]-lowerB_save[iter])/upperB_save[iter]:.4f}\")\n",
    "            print(\"Upper bound :\", upperB_save[iter])\n",
    "            print(\"Lower bound :\", lowerB_save[iter])\n",
    "            print(f\"[Outer Loop] Terminate the optimization process after {iter} outer iterations.\")\n",
    "            print(f\"\\t Termination Conditions: \\n\\t\\tconfidence_adjusted_bound_gap = {confidence_adjusted_bound_gap}, R_div = {R_div}\")\n",
    "            print(f\"\\tupper_confidence_bound: {upperB_save[iter]}, lower_bound: {lowerB_save[iter]}\")\n",
    "            break\n",
    "\n",
    "        print(\"---> NOT BREAKING ---\")\n",
    "        print(f\"     upper_confidence_bound: {upper_confidence_bound}, lower_bound: {lowerB_save[iter]}, confidence_adjusted_bound_gap = {confidence_adjusted_bound_gap}\")\n",
    "        print(f\"     Iter Count: {iter}\")\n",
    "        print(\"<--- \")\n",
    "\n",
    "        # Continuing iteration\n",
    "        iter+=1\n",
    "        R_div = max(int(np.ceil(R_div / 1.5)), 1)\n",
    "\n",
    "    total_time = dt.datetime.now() - start_time\n",
    "\n",
    "    # Saving all files to analyze in another code\n",
    "    res_path = 'res/single'\n",
    "    os.makedirs(res_path, exist_ok=True)\n",
    "    np.save(res_path+'/obj_2nd.npy', obj_2nd[:,:iter])\n",
    "    np.save(res_path+'/lambda_2nd.npy', lambda_2nd[:,:,:,:iter])\n",
    "    np.save(res_path+'/mu_2nd.npy', mu_2nd[:,:,:,:iter])\n",
    "    np.save(res_path+'/previous_rating.npy', previous_rating[:,:iter])\n",
    "    np.save(res_path+'/previous_cap.npy', previous_cap[:,:iter])\n",
    "    np.save(res_path+'/ESS_loc.npy', ESS_loc[:,:iter])\n",
    "    np.save(res_path+'/alpha_store.npy', alpha_store[:iter])\n",
    "    np.save(res_path+'/upperB_save.npy', upperB_save[:iter])\n",
    "    np.save(res_path+'/lowerB_save.npy', lowerB_save[:iter])\n",
    "    np.save(res_path+'/invest_save.npy', invest_save[:iter])\n",
    "    np.save(res_path+'/Elapsed_time.npy', Elapsed_time[:iter])\n",
    "    np.save(res_path+'/total_time.npy', total_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e6fc24",
   "metadata": {},
   "source": [
    "### Newcut Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newcut(cb, cb_where):\n",
    "    if cb_where == GRB.Callback.MIPSOL:\n",
    "        global cutPoolLazy, cutPoolInfeas, cutPoolPartial\n",
    "        global cutPoolLazy_added, z_last, gap_last, objval_last, bnd_last\n",
    "        global nCuts, countLazy, R_sample, t_cur, objVal_cur, objVal_inner\n",
    "        global z, t, z0, c, A, b, u, n, nR, R_div, method\n",
    "        global cmcmd_prob, config, infeas_r\n",
    "\n",
    "        if not cutPoolLazy_added:\n",
    "            if len(cutPoolLazy) > 0:\n",
    "                print(f\"[Newcut] Adding {len(cutPoolLazy)} optimality lazy cuts from previous outer iterations\")\n",
    "                for lazyCut in cutPoolLazy:\n",
    "                    if lazyCut.method == \"scp_slim\" and method == \"scp_slim\":\n",
    "                        expr = lazyCut.offset[0] + sum(lazyCut.slope[i] * z[i] for i in range(len(z)))\n",
    "                        cb.cbLazy(t >= expr)\n",
    "            \n",
    "            if len(cutPoolInfeas) > 0:\n",
    "                print(f\"[Newcut] Adding {len(cutPoolInfeas)} infeasibility lazy cuts from previous outer iterations\")\n",
    "                for c_cut in cutPoolInfeas:\n",
    "                    for r in range(c_cut.b.shape[1]):\n",
    "                        if (np.any(c_cut.b[:,r] > 0) or np.any(c_cut.p[:,:,r] != 0)):\n",
    "                            r_tilde = c_cut.R_sample[r]\n",
    "                            lhs = np.sum(c_cut.p[:,:,r] * b[:,:,r_tilde])\n",
    "                            rhs = sum(z[e] * u[e] * c_cut.b[e, r] for e in range(n))\n",
    "                            cb.cbLazy(lhs <= rhs)\n",
    "            \n",
    "            cutPoolLazy_added = True\n",
    "\n",
    "        z_cur = np.zeros(len(z0))\n",
    "        for i in range(n):\n",
    "            z_cur[i] = cb.cbGetSolution(z[i])\n",
    "\n",
    "        if config.round_z0:\n",
    "            z_cur = np.round(z_cur, decimals=3)\n",
    "\n",
    "        primal_bound = cb.cbGet(GRB.Callback.MIPSOL_OBJBST)\n",
    "        dual_bound = cb.cbGet(GRB.Callback.MIPSOL_OBJBND)\n",
    "        objbst = primal_bound\n",
    "        objbnd = dual_bound\n",
    "        mip_gap = min(gapcalculate(objbst, objbnd), 1)\n",
    "\n",
    "        node_count = cb.cbGet(GRB.Callback.MIPSOL_NODCNT)\n",
    "\n",
    "        if node_count >= 0:\n",
    "            is_zcur_feasible = cMCMD_is_feasible(A, b, z_cur, u)\n",
    "            print(f\" [Newcut] Status : {node_count} --- Saving z_last\\n\\t\\tis_zcur_feasible = {is_zcur_feasible} --- ({np.sum(z_cur)}/{len(z_cur)})\")\n",
    "            if is_zcur_feasible:\n",
    "                z_last = z_cur.copy()\n",
    "                gap_last = mip_gap\n",
    "                objval_last = objbst\n",
    "                bnd_last = max(objbnd, bnd_last)\n",
    "\n",
    "        R_sample = np.sort(np.random.choice(range(nR), size=int(np.ceil(nR/R_div)), replace=False))\n",
    "        print(f\"\\t\\t\\tR_sample : {R_sample}\")\n",
    "\n",
    "        add_infeasibility_cut = False\n",
    "        if method == \"scp_slim\":\n",
    "            nCuts += 1\n",
    "            \n",
    "            print(\" [Newcut] Calculating Cut\")\n",
    "            obj, grad_obj, feas_status, _ = cMCMDCutting_plane(\n",
    "                cmcmd_prob, config, z_cur, R_sample=R_sample\n",
    "            )\n",
    "            add_infeasibility_cut = np.any(np.isnan(obj))\n",
    "            \n",
    "            if add_infeasibility_cut and config.use_partial_cuts:\n",
    "                R_sample_partial = np.setdiff1d(R_sample, R_sample[infeas_r])\n",
    "                if len(R_sample_partial) >= 1:\n",
    "                    print(f\"\\t\\t[use_partial_cuts] Adding {len(R_sample_partial)} optimality cuts for infeasible z\")\n",
    "                    obj_partial, grad_obj_partial, feas_status = cMCMDCutting_plane(\n",
    "                        cmcmd_prob, config, z_cur, R_sample=R_sample_partial\n",
    "                    )\n",
    "                    if np.isnan(obj_partial):\n",
    "                        raise ValueError(\"\\t\\t\\t[use_partial_cuts] NaN obj_partial\")\n",
    "                    else:\n",
    "                        expr = obj_partial + sum(grad_obj_partial[i] * (z[i] - z_cur[i]) for i in range(n))\n",
    "                        cb.cbLazy(t >= expr)\n",
    "\n",
    "                        s0 = type.PrimalSolution(\n",
    "                            np.where(z_cur > 0)[0].tolist(), \n",
    "                            z_cur.tolist(), \n",
    "                            obj_partial + np.dot(c, z_cur),\n",
    "                            [obj_partial - np.dot(grad_obj_partial, z_cur[:n])],\n",
    "                            grad_obj_partial, \n",
    "                            False, \n",
    "                            method, \n",
    "                            R_sample.tolist(), \n",
    "                            [], \n",
    "                            {}\n",
    "                        )\n",
    "                        cutPoolPartial.append(s0)\n",
    "            \n",
    "            if not add_infeasibility_cut:\n",
    "                expr = obj + sum(grad_obj[i] * (z[i] - z_cur[i]) for i in range(n))\n",
    "                cb.cbLazy(t >= expr)\n",
    "                print(\"\\t[Newcut] Adding Slim Cut\")\n",
    "\n",
    "                s0 = PrimalSolution(\n",
    "                    np.where(z_cur > 0)[0].tolist(), \n",
    "                    z_cur.tolist(),\n",
    "                    obj + np.dot(c, z_cur),\n",
    "                    [obj - np.dot(grad_obj, z_cur[:n])],\n",
    "                    grad_obj, \n",
    "                    False, \n",
    "                    method, \n",
    "                    R_sample.tolist(), \n",
    "                    {}\n",
    "                )\n",
    "                cutPoolLazy.append(s0)\n",
    "                countLazy += 1\n",
    "                if countLazy % 10 == 0:\n",
    "                    print(f\"countlazy = {countLazy}\")\n",
    "        \n",
    "        if add_infeasibility_cut:\n",
    "            p_certificate, beta_certificate, infeas_r = get_infeas_certificate(cmcmd_prob, z_cur, R_sample=R_sample)\n",
    "            print(f\"[Newcut] Adding Infeasibility Cut\\n\\t\\tR_sample = {R_sample}\\n\\t\\tinfeas_r = {R_sample[infeas_r]}\")\n",
    "\n",
    "            if not (np.any(np.isnan(p_certificate)) and np.any(np.isnan(beta_certificate))):\n",
    "                for r in infeas_r:\n",
    "                    if (np.any(beta_certificate[:,r] > 0) or np.any(p_certificate[:,:,r] != 0)):\n",
    "                        r_tilde = R_sample[r]\n",
    "                        LHS_check = np.sum(p_certificate[:,:,r] * b[:,:,r_tilde]) - sum(z_cur[e] * u[e] * beta_certificate[e, r] for e in range(n))\n",
    "                        print(f\"\\t\\t\\tAdding cut for r = {r} (r_tilde = {r_tilde}) [LHS_check at z_cur = {LHS_check}]\")\n",
    "\n",
    "                        lhs = np.sum(p_certificate[:,:,r] * b[:,:,r_tilde])\n",
    "                        rhs = sum(z[e] * u[e] * beta_certificate[e, r] for e in range(n))\n",
    "                        cb.cbLazy(lhs <= rhs)\n",
    "\n",
    "                infeas_cut = type.InfeasibleCut(\n",
    "                    z_cur.tolist(), \n",
    "                    R_sample.tolist(), \n",
    "                    p_certificate, \n",
    "                    beta_certificate, \n",
    "                    infeas_r\n",
    "                )\n",
    "                cutPoolInfeas.append(infeas_cut)\n",
    "        \n",
    "        if method == \"scp_slim\":\n",
    "            t_cur = cb.cbGetSolution(t)\n",
    "\n",
    "            objVal_cur = np.dot(c, z_cur) + t_cur\n",
    "            objVal_inner = np.dot(c, z_cur) + obj\n",
    "\n",
    "            print(f\"[Newcut End Logging]\\n  --objbst = {objbst}\\n  --objbnd = {objbnd}\\n  --mip_gap = {mip_gap}\\n  --objVal_cur = {objVal_cur}\\n  --objVal_inner = {objVal_inner}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvxpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
